# Grilles d'Évaluation - Hackathon "Agricola Numerica"

Ce document détaille les grilles critériées utilisées pour l'évaluation du hackathon.

**Échelle de notation commune :**
Chaque critère est évalué sur une échelle de 1 à 4.
- **1 : En dessous des attentes** (Les objectifs de base ne sont pas atteints)
- **2 : Conforme aux attentes** (Les objectifs sont atteints de manière fonctionnelle)
- **3 : Au-dessus des attentes** (Les objectifs sont dépassés, avec des initiatives ou une qualité notable)
- **4 : Exceptionnel** (Prestation exemplaire qui peut servir de modèle, impact majeur)

---

## 1. Auto-évaluation & Évaluation par les Pairs

*Cette grille est à remplir par chaque membre pour s'auto-évaluer et pour évaluer chaque membre de son équipe.*

| Critère | Description | Note (1-4) | Justification (Exemples concrets) |
| :--- | :--- | :--- | :--- |
| **Contribution Technique** | Qualité et quantité du code produit, pertinence des solutions techniques proposées, aide apportée sur les aspects techniques. | | |
| **Collaboration & Communication** | Participe activement aux discussions, communique clairement ses avancées et ses blocages, est à l'écoute et respectueux des autres. | | |
| **Fiabilité & Engagement** | Respecte les engagements pris, est présent et impliqué dans les rituels de l'équipe, fait preuve d'autonomie et de proactivité. | | |

---

## 2. Évaluation Finale par le Jury

*Cette grille est utilisée par le jury pour évaluer la performance collective de l'équipe lors de la présentation finale.*

### 2.1 Qualité de la Démonstration

| Critère | Description | Note (1-4) | Commentaires du Jury |
| :--- | :--- | :--- | :--- |
| **Fluidité du Scénario** | La démonstration raconte une histoire de jeu cohérente et fluide, de la création de la partie à la fin de quelques tours, sans accroc majeur. | | |
| **Robustesse de l'Application** | L'application fonctionne sans bugs bloquants ou erreurs visibles. Le lancement via `docker-compose up` est fonctionnel et rapide. | | |
| **Complétude & Complexité** | Les fonctionnalités clés (création partie, action, temps réel, récolte) sont implémentées et fonctionnelles. La complexité gérée est évaluée. | | |
| **Clarté des Explications** | L'équipe explique clairement le flux technique (API Gateway -> Service -> RabbitMQ -> WebSocket -> Frontend) et justifie ses choix d'architecture. | | |

### 2.2 Qualité de la Rétrospective

| Critère | Description | Note (1-4) | Commentaires du Jury |
| :--- | :--- | :--- | :--- |
| **Honnêteté & Pertinence** | L'équipe présente une analyse lucide et honnête des succès, des échecs et des difficultés rencontrées, sans chercher d'excuses. | | |
| **Apprentissages Clés** | L'équipe articule clairement les leçons apprises, tant sur le plan technique (ex: "l'importance des contrats d'API") que sur le plan humain (ex: "comment mieux communiquer"). | | |
| **Qualité de la Présentation** | La rétrospective est bien structurée, concise et engageante. Tous les membres de l'équipe semblent impliqués et partagent une vision commune. | | |
